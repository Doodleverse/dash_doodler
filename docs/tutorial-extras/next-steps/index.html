<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.73">
<link rel="alternate" type="application/rss+xml" href="/dash_doodler/blog/rss.xml" title="Doodler Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/dash_doodler/blog/atom.xml" title="Doodler Blog Atom Feed"><title data-react-helmet="true">[ADVANCED] Next steps .... training a Deep Learning model for image segmentation | Doodler</title><meta data-react-helmet="true" property="og:url" content="https://dbuscombe-usgs.github.io/dash_doodler/docs/tutorial-extras/next-steps"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="[ADVANCED] Next steps .... training a Deep Learning model for image segmentation | Doodler"><meta data-react-helmet="true" name="description" content="(page under construction)"><meta data-react-helmet="true" property="og:description" content="(page under construction)"><link data-react-helmet="true" rel="shortcut icon" href="/dash_doodler/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://dbuscombe-usgs.github.io/dash_doodler/docs/tutorial-extras/next-steps"><link data-react-helmet="true" rel="alternate" href="https://dbuscombe-usgs.github.io/dash_doodler/docs/tutorial-extras/next-steps" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://dbuscombe-usgs.github.io/dash_doodler/docs/tutorial-extras/next-steps" hreflang="x-default"><link rel="stylesheet" href="/dash_doodler/assets/css/styles.8f634425.css">
<link rel="preload" href="/dash_doodler/assets/js/styles.f681044a.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/runtime~main.fdeca4e3.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/main.3eb69755.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/1.aeae5514.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/2.343bca5c.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/60.948fbc65.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/62.c3115978.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/935f2afb.a930908d.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/17896441.e9523a68.js" as="script">
<link rel="preload" href="/dash_doodler/assets/js/881af93b.22d8275a.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#main" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle" type="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/dash_doodler/"><img src="/dash_doodler/img/doodler-logo.png" alt="My Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/dash_doodler/img/doodler-logo.png" alt="My Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title"></strong></a><a class="navbar__item navbar__link navbar__link--active" href="/dash_doodler/docs/intro">Tutorials</a><a class="navbar__item navbar__link" href="/dash_doodler/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/dbuscombe-usgs/dash_doodler" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Doodler github page</a><div class="react-toggle displayOnlyInLargeViewport_GrZ2 react-toggle--disabled" role="button" tabindex="-1"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/dash_doodler/"><img src="/dash_doodler/img/doodler-logo.png" alt="My Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/dash_doodler/img/doodler-logo.png" alt="My Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title"></strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link navbar__link--active" href="/dash_doodler/docs/intro">Tutorials</a></li><li class="menu__list-item"><a class="menu__link" href="/dash_doodler/blog">Blog</a></li><li class="menu__list-item"><a href="https://github.com/dbuscombe-usgs/dash_doodler" target="_blank" rel="noopener noreferrer" class="menu__link">Doodler github page</a></li></ul></div></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_31aa"><div class="docSidebarContainer_3Kbt" role="complementary"><div class="sidebar_15mo"><div class="menu menu--responsive thin-scrollbar menu_Bmed"><button aria-label="Open menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_fgN0" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/dash_doodler/docs/intro">What is Doodler for?</a></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Doodler - Basics</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/tutorial-basics/deploy-local">Installing Doodler on a PC for your own use</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/tutorial-basics/what-to-do">What to do</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/tutorial-basics/how-to-doodle">How to Doodle well</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/tutorial-basics/utilities">Utility scripts</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/tutorial-basics/faqs">Frequently Asked Questions</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/tutorial-basics/getting-help">Getting help</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Doodler - Extras</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/dash_doodler/docs/tutorial-extras/how-doodler-works">[ADVANCED] How Doodler works</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/dash_doodler/docs/tutorial-extras/deploy-server">[ADVANCED] Serving Doodler as a web application for others to use</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/dash_doodler/docs/tutorial-extras/how-to-contribute">[ADVANCED] How to contribute</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/dash_doodler/docs/tutorial-extras/next-steps">[ADVANCED] Next steps .... training a Deep Learning model for image segmentation</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/dash_doodler/docs/tutorial-extras/references">[ADVANCED] References</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Case Studies</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/case-studies/case-study1">Case Study 1: Greyscale geophysical imagery</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/dash_doodler/docs/case-studies/case-study2">Case Study 3: NOAA post-hurricane reconnaissance aerial imagery</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3ufF"><div class="container padding-vert--lg docItemWrapper_3FMP"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><header><h1 class="docTitle_3a4h">[ADVANCED] Next steps .... training a Deep Learning model for image segmentation</h1></header><div class="markdown"><p>(page under construction)</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="utility-scripts"></a>Utility scripts<a class="hash-link" href="#utility-scripts" title="Direct link to heading">#</a></h3><p>Doodler is compatible with the segmentation program, <a href="https://github.com/dbuscombe-usgs/segmentation_zoo" target="_blank" rel="noopener noreferrer">Zoo</a> in a couple of different ways:</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="scenario-1-most-common"></a>Scenario 1 (most common)<a class="hash-link" href="#scenario-1-most-common" title="Direct link to heading">#</a></h4><p>You wish to generate labels and images for subsequent use in Zoo, specifically to make a dataset to train or test an image segmentation model</p><blockquote><p>run the function <code>gen_images_and_labels_4_zoo.py</code></p></blockquote><p>This will generate 4 folders, 1 for each of the output types</p><ol><li>images:<blockquote><p>The images you doodled</p></blockquote></li></ol><p><img src="/dash_doodler/assets/images/rgb-e90e75ff8b6e39a2b9a30df7c5638224.jpg"></p><ol start="2"><li>labels<blockquote><p>The color and greyscale label images</p></blockquote></li></ol><p><img src="data:image/png;base64,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"></p><p>and greyscale</p><p><img src="data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCADlAZgBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AP5/6KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKcJpAu0Nx9KVZJCfvfpSkk9f5UBQei/pSkIIyNhzjrioqKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKcEPenAAdBQAT0FPVdtEn+rJqCiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiilCE9eKcFApQCTgU4J607pwBSqhPLDHtRcD90cVWooooooooooooooooooooooooooooooooooooooooopQpNOVQtLShSaeABwKUIT1pwQDryR3paZP/qm+lVqKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKcE7n8qdShSacAB0FOCk05VC0tFFMn/1TfSq1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFABJwKUIT14pwAHQUoBPQU9UAOaUAnoKeqAHNLRRRRTJziI1WooooooooooooooooooooooooooooooooooooAJOBTlQd6UADoKUAk4FOCdz+VOA7AU5UHenUUUUUUUyf/VGq1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFOVB3pQAOgpQCTgU4J3P5U4ADgUoQnrxTwAOBRRRRQCDyKKKKZcDMRqtRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRTgnc/lShQDkClpQhPXinAAdBTgpNOCgUtFFFFIRkYoHHGOKWiimT/AOqb6VWoooooooooooooooooooooooooooooopyoc80oAHQUtKEOeacqhaUAnoKcEA6806iiiiiiikIyMULkDBFLRTJ/9U30qtRRRRRRRRRRRRRRRRRRRRRRRRRRRRTgnc/lTgAOBRShSacFApQCegpwQDrzTgAOBRRRRRRRRRRRRRTLj/VGq1FFFFFFFFFFFFFFFFFFFFFFFFFABJwKUIT14pwAHQUtKEJ68U4ADoKUAnoKcEA6806iiiiiiiiiiiiiiimXH+qNViMHFFFFFFFFFFFFFFFFFFFFFFFFKFJ5ApQnc/lTqKUIT14pwAHQUoBPQU4IB15p1FFFFFFFFFFFFFFFFH0pB864cfWqjdT9aKKKKKKKKKKKKKKKKKKKKKXY3pTlQA5paACTgU4Ie5pQoFLSqpPOcU8Z7miiiiiiiiiiiiiiiiiiiiqbdT9aKKKKKKKKKKKKKKKKKKKVVzTti0tGCegpwT1NOAA4FGCegpQhPWnbF9KWiiiiiiiiiiiiiiiiiiiiiqbdT9aKKKKKKKKKKKKKKKKKVVzSlPQ06jBPQU4J6mnYA6CgAk8U8IAaXAHQUUUUUUUUUUUUUUUUUUUUUUUUVTbqfrRRRRRRRRRRRRRRRgnoKXYfUU4KBS0AEninBPU07AHQUYJ6CnBAOtOwB0FNklSMcnn0qH7VJ/dX8qmjLMgZxgmnUUUUUUUUUUUUUUUUUUUUUUVTbqfrRRRRRRRRRRRRQASeKcqYPNOwB0FFABJ4pwQdzTsAdBShSadtVRk/rSeZEOjr+dI88aDg5+lQrLMQQuTnv6Uwksck5+tTQQZ+dx9AafOrlcxkjHYVCs8seQef96l+1Sf3V/Knx3KtgPwfXtUoIYZBz9KKKKKKKKKKKKKKKKKKKKpt1P1ooooooooooopypkZNOwB0FFGD6GnbBnrTgPQUoQnrTsKoycfU0yS4AO2MZNAid8mVzz2U0jWq4+Rjn3NIlr/fb6YNSqir91QPwpjW8bNu5HsKkopCiE5KA/hTGto2JIyPYVC8TxnkfiKWKUxsMk49KsghhkGiiiiiiiiiiiiiiiiiiqbdT9aKKKKKKKKKUKTShB3NOAwMUoUmnBQKWnKmetKFA7U150Qdc/SogJp8nOB+lSxwpHyBk+pp9FFFFFFFFBAYYIz9aYYYywbaOOwFPAAGAMUUUUUUUUUUUUUUUUUUVTbqfrRRRRRRShSacEANG0Z6UtKEJpwUDtS4J6CnBPU0p2qNxwKj+1R/3W/KmNLLI2FyPpSi1fPzMMd8GpkQIu0dqWiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiqbdT9aKKKKME9BTghzyadRShSacFApacEOeTTsAdBQSAMk4qC4lDnap4HWoqltUyd57dKnooooooooooooooooooooooooooooooooqm3U/WiilCk9qXYPU0oAHSlpQpNOCAGlpVGT1pyqF5NNeeNO+fpTWulx8qnPbIqOSZ5OCcewpgBY4Az9Kkjt2bBbgdx3qdECLtHalooooooooooooooooooooooooooooooooqm3U/WgAk8U8KBS0UoUntTlXFLRRSrwc1FJM8jYTIHYCkSCR+2PrTvssndh+dO+yx/wB5vzqQIi8hQPfFLRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRVULljnpmlAA6UtABJ4pwQDrTqKKQugGdw/OmmdccA596aZnIxwPcVLDEqqG4JPepKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKrJliV96eFB70bB6mnYA6CmNKqnA5pVkVhkkChpEUZzn6Ux5WY4XihYJHPTH1pWt5FGeD7CoyCDgjFTW82P3bHjsamooooooooooooooooooooooooooooooooooooooqCJeS3vT8AdBRUcsjA7RxUYBJwBk09IJH7Y+tL9lk/vL+dSpAiDpn60+imSwrIMgYPrVcgqcEYNWIZfMXnqKfRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRUMX3fxp1FKsascsoP1FOCIDkIB+FLRRRRRTZIkkHI59agBeCTH51YR1cblNLRRRRRRRRRRRRRRRRRRSFlX7zAfU0b0zt3DPpmloooooooooooooooqCEkqR71LsHqaUKBS0UUU1HLMynseKbPM0ZAUDn1qP7VJ/dX8qPtUn91fyo+1Sf3V/KmySGQ5IH4UgZl+6xH0NHmSf8APRvzo8yT/no350eZJ/z0b86PMk/56N+dHmSf89G/OjzJP+ejfnR5kn/PRvzo8yT/AJ6N+dHmSf8APRvzo8yT/no350eZJ/z0b86PMk/56N+dHmSf89G/OjzJP+ejfnR5kn/PRvzo8yT/AJ6N+dOSeRO+frS/apP7q/lTWmkY53EewNIWZvvMT9TRubO7Jz60eZJ/z0b86PMk/wCejfnR5kn/AD0b86PMk/56N+dHmSf89G/OjzJP+ejfnR5kn/PRvzo8yT/no350eZJ/z0b86PMk/wCejfnR5kn/AD0b86PMk/vn86N7/wB4/nRub+8fzpMk9TRX/9k="></p><ol start="3"><li>doodles<blockquote><p>The image with the color doodles as a semi-transparent overlay</p></blockquote></li></ol><p><img src="/dash_doodler/assets/images/doodled-6ac39393de385764d3688946381e25ac.png"></p><ol start="4"><li>overlays<blockquote><p>The image with the color label as a semi-transparent overlay</p></blockquote></li></ol><p><img src="/dash_doodler/assets/images/overlay-eedb335477469d5e3add870a5c42599c.png"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="scenario-2"></a>Scenario 2<a class="hash-link" href="#scenario-2" title="Direct link to heading">#</a></h4><p>You wish to use the labels and images in Zoo, but wish to bypass running the Zoo program `make_datasets.py&#x27;, i.e. you&#x27;d like to pass the original labels and images to the model training rather than create augmented outputs of a certain size</p><blockquote><p>run the function <code>gen_npz_4_zoo.py</code> to create npz files that contain only image and label pairs.</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="deep-learning-for-image-segmentation"></a>Deep Learning for Image Segmentation<a class="hash-link" href="#deep-learning-for-image-segmentation" title="Direct link to heading">#</a></h3><p>There are two main drawbacks with neural networks consisting of only dense layers for classifying images:</p><ul><li><p>Too many parameters means even simple networks on small and low-dimensional imagery take a long time to train</p></li><li><p>There is no concept of spatial distance, so the relative proximity of image features or that with respect to the classes, is not considered</p></li></ul><p>For both the reasons above, Convolutional Neural Networks or CNNs have become popular for working with imagery. CNNs train in a similar way to &quot;fully connected&quot; ANNs that use Dense layers throughout.</p><p>CNNs can handle multidimensional data as inputs, meaning we can use 3- or more band imagery, which is typical in the geosciences. Also, each neuron isn&#x27;t connected to all others, only those within a region called the receptive field of the neuron, dictated by the size of the convolution filter used within the layer to extract features from the image. By linking only subsets of neurons, there are far fewer parameters for a given layer</p><p>So, CNNS take advantage of both multidimensionality and local spatial connectivity</p><p>CNNs tend to take relatively large imagery and extract smaller and smaller feature maps. This is achieved using pooling layers, which find and compress the features in the feature maps outputted by the CNN layers, so images get smaller and features are more pronounced</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="u-net"></a>U-Net<a class="hash-link" href="#u-net" title="Direct link to heading">#</a></h2><p>Introduced in 2015, the U-Net model is relatively old in the deep learning field (!) but still popular and is also commonly seen embedded in more complex deep learning models</p><p>The U-Net model is a simple fully convolutional neural network that is used for binary segmentation i.e foreground and background pixel-wise classification. Mainly, it consists of two parts.</p><ul><li>Encoder: we apply a series of conv layers and downsampling layers (max-pooling) layers to reduce the spatial size</li><li>Decoder: we apply a series of upsampling layers to reconstruct the spatial size of the input.
The two parts are connected using a concatenation layers among different levels. This allows learning different features at different levels. At the end we have a simple conv 1x1 layer to reduce the number of channels to 1.</li></ul><p>U-Net is symmetrical (hence the &quot;U&quot; in the name) and uses concatenation instead of addition to merge feature maps</p><p>The encoder (left hand side of the U) downsamples the N x N x 3 image progressively using six banks of convolutional filters, each using filters double in size to the previous, thereby progressively downsampling the inputs as features are extracted through max pooling</p><p>A &#x27;bottleneck&#x27; is just machine learning jargon for a very low-dimensional feature representation of a high dimensional input. Or, a relatively small vector of numbers that distill the essential information about a large image An input of N x N x 3 (&gt;&gt;100,000 numbers) has been distilled to a &#x27;bottleneck&#x27; of 16 x 16 x M (&lt;&lt;100,000 numbers)</p><p>The decoder (the right hand side of the U) upsamples the bottleneck into a N x N x 1 label image progressively using six banks of convolutional filters, each using filters half in size to the previous, thereby progressively upsampling the inputs as features are extracted through transpose convolutions and concatenation. A transposed convolution is a relatively new type of deep learning model layer that convolves a dilated version of the input tensor, in order to upscale the output. The dilation operation consists of interleaving zeroed rows and columns between each pair of adjacent rows and columns in the input tensor. The dilation rate is the stride length</p><p>Finally, make the classification layer using one final convolutional layers that essentially just maps (by squishing over 16 layers) the output of the previous layer to a single 2D output (with values ranging from 0 to 1) based on a sigmoid activation function</p></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/dbuscombe-usgs/dash_doodler/edit/master/website/docs/tutorial-extras/next-steps.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" role="img" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-label="Edit page"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/dash_doodler/docs/tutorial-extras/how-to-contribute"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« [ADVANCED] How to contribute</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/dash_doodler/docs/tutorial-extras/references"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">[ADVANCED] References Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#utility-scripts" class="table-of-contents__link">Utility scripts</a></li><li><a href="#deep-learning-for-image-segmentation" class="table-of-contents__link">Deep Learning for Image Segmentation</a></li><li><a href="#u-net" class="table-of-contents__link">U-Net</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Docs</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/dash_doodler/docs/intro">Tutorials</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://github.com/dbuscombe-usgs/coast_train" target="_blank" rel="noopener noreferrer" class="footer__link-item">Coast Train</a></li><li class="footer__item"><a href="https://www.usgs.gov/centers/pcmsc/science/remote-sensing-coastal-change?qt-science_center_objects=0#qt-science_center_objects" target="_blank" rel="noopener noreferrer" class="footer__link-item">USGS Remote Sensing Coastal Change</a></li><li class="footer__item"><a href="https://coastalimagelabeler.science/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Coastal Image Labeler by Dr Evan Goldstein</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">More</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/dash_doodler/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/dbuscombe-usgs/dash_doodler" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github</a></li><li class="footer__item"><a href="https://www.makesense.ai/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Makesense.ai (an alternative way to segment imagery)</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Doodler is written and maintained by Daniel Buscombe, Marda Science, LLC, contracted to the U.S. Geological Survey Pacific Coastal and Marine Science Center in Santa Cruz, CA. Doodler development is funded by the U.S. Geological Survey Coastal Hazards Program, and is for the primary usage of U.S. Geological Survey scientists, researchers and affiliated colleagues working on the Hurricane Florence Supplemental Project and other coastal hazards research. Thanks to Jon Warrick, Phil Wernette, Chris Sherwood, Jenna Brown, Andy Ritchie, Jin-Si Over, Christine Kranenburg, and the rest of the Florence Supplemental team; to Evan Goldstein and colleagues at University of North Carolina Greensboro; Leslie Hsu at the USGS Community for Data Integration; and LCDR Brodie Wells, formerly of Naval Postgraduate School, Monterey. Copyright Â© 2021 Marda Science, LLC. </div></div></div></footer></div>
<script src="/dash_doodler/assets/js/styles.f681044a.js"></script>
<script src="/dash_doodler/assets/js/runtime~main.fdeca4e3.js"></script>
<script src="/dash_doodler/assets/js/main.3eb69755.js"></script>
<script src="/dash_doodler/assets/js/1.aeae5514.js"></script>
<script src="/dash_doodler/assets/js/2.343bca5c.js"></script>
<script src="/dash_doodler/assets/js/60.948fbc65.js"></script>
<script src="/dash_doodler/assets/js/62.c3115978.js"></script>
<script src="/dash_doodler/assets/js/935f2afb.a930908d.js"></script>
<script src="/dash_doodler/assets/js/17896441.e9523a68.js"></script>
<script src="/dash_doodler/assets/js/881af93b.22d8275a.js"></script>
</body>
</html>